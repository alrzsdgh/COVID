{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown\n!gdown --id 1N0jmtIJkzRrPJHpXpk8mlM5JPirL6_Gb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip '/kaggle/working/Train&Validation.zip' -d '/kaggle/working/Data'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nfrom tqdm import tqdm\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy import ndimage\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.remove('/kaggle/working/Train&Validation.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making different folders for different patients\nif os.path.exists('/kaggle/working/Patients') == False:\n    os.mkdir('/kaggle/working/Patients')\n    \nif os.path.exists('/kaggle/working/Patients/Normal') == False:\n    os.mkdir('/kaggle/working/Patients/Normal')\n    \nif os.path.exists('/kaggle/working/Patients/COVID') == False:\n    os.mkdir('/kaggle/working/Patients/COVID')\n\nfor item in tqdm(os.listdir('/kaggle/working/Data')):\n    idx1 = item.find('patient')\n    idx2 = item[idx1:].find('_')\n    patient_num = item[idx1: idx1 + idx2]\n    \n    src_dir = '/kaggle/working/Data/' + item\n    \n    if 'normal' in item:\n        des_dir = '/kaggle/working/Patients/Normal/' + patient_num\n    elif 'covid' in item:\n        des_dir = '/kaggle/working/Patients/COVID/' + patient_num\n\n    if os.path.exists(des_dir):\n        shutil.move(src_dir, des_dir)\n    else:\n        os.mkdir(des_dir)\n        shutil.move(src_dir, des_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_volume(img):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = 128\n    desired_width = 128\n    desired_height = 128\n    # Get current depth\n    current_depth = img.shape[0]\n    current_width = img.shape[1]\n    current_height = img.shape[2]\n    # Compute depth factor\n    depth = current_depth / desired_depth\n    width = current_width / desired_width\n    height = current_height / desired_height\n    depth_factor = 1 / depth\n    width_factor = 1 / width\n    height_factor = 1 / height\n    # Resize across z-axis\n    img = ndimage.zoom(img, (depth_factor, width_factor, height_factor, 1))\n    return img\n\n\n\n\ndef plot_slices(num_rows, num_cols, data):\n    # create figure\n    fig = plt.figure(figsize=(10, 7))\n    \n    n = len(data)\n  \n    for i in range(num_rows * num_cols):\n        if i < n:\n            # Adds a subplot at the 1st position\n            fig.add_subplot(num_rows, num_cols, i+1)\n\n            # showing image\n            plt.imshow(data[i])\n            plt.axis('off')\n            \n            \n      \n    \n    \ndef prepare_3D_samples(main_dir, inp_lst):\n    \n    final_lst = []\n    for i in tqdm(inp_lst):\n        tmp_dir = os.path.join(main_dir,i)\n        tmp_lst = os.listdir(tmp_dir)\n        tmp_lst.sort()\n        \n        tmp_3d = []\n        for j in tmp_lst:\n            tmp_3d.append(plt.imread(os.path.join(main_dir,i,j)))\n        \n        tmp_3d = np.expand_dims(tmp_3d, axis = -1)\n        final_lst.append(resize_volume(np.array(tmp_3d)))\n    return np.array(final_lst)\n\n\n\n\ndef rotate(volume):\n    \"\"\"Rotate the volume by a few degrees\"\"\"\n\n    def scipy_rotate(volume):\n        # define some rotation angles\n        angles = [-20, -10, -5, 0, 5, 10, 20]\n        # pick angles at random\n        angle = random.choice(angles)\n        # rotate volume\n        volume = ndimage.rotate(volume, angle, reshape=False)\n        return volume\n    \n    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n    return augmented_volume","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cov_main_dir = '/kaggle/working/Patients/COVID'\nnorm_main_dir = '/kaggle/working/Patients/Normal'\n\ncov_lst = os.listdir(cov_main_dir)\ncov_lst.sort()\nrandom.Random(1).shuffle(cov_lst)\n\nnorm_lst = os.listdir(norm_main_dir)\nnorm_lst.sort()\nrandom.Random(1).shuffle(norm_lst)\n\nprint(len(cov_lst))\nprint(cov_lst[:5])\nprint(len(norm_lst))\nprint(norm_lst[:5])\nprint('_________')\n\ncovid_volume = prepare_3D_samples(cov_main_dir, cov_lst)\nnormal_volume = prepare_3D_samples(norm_main_dir, norm_lst)\nprint('_________')\n\nprint('covid_volume:', np.shape(covid_volume))\nprint('normal_volume:', np.shape(normal_volume))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normal_labels = np.array([1 for _ in range(len(normal_volume))])\ncovid_labels = np.array([0 for _ in range(len(covid_volume))])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.concatenate((covid_volume[:76], normal_volume[:225]), axis=0)\ny_train = np.concatenate((covid_labels[:76], normal_labels[:225]), axis=0)\n\nx_valid = np.concatenate((covid_volume[76:], normal_volume[225:]), axis=0)\ny_valid = np.concatenate((covid_labels[76:], normal_labels[225:]), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('x_train:', np.shape(x_train))\nprint('y_train:', np.shape(y_train))\nprint('x_valid:', np.shape(x_valid))\nprint('y_valid:', np.shape(y_valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize a sample in x_train\n\nprint('label:',y_train[10])\nprint('label 1 is normal and label 0 is covid 19')\n\nplot_slices(8,10,x_train[10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_preprocessing(volume, label):\n    # rescaling\n    volume = tf.cast(volume, tf.float32) / 255.0\n    # Rotate volume\n    volume = rotate(volume)\n    return volume, label\n\n\ndef validation_preprocessing(volume, label):\n    # rescaling\n    volume = tf.cast(volume, tf.float32) / 255.0\n    return volume, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define data loaders.\ntrain_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalidation_loader = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n\nbatch_size = 2\n\n# Augment the on the fly during training.\ntrain_dataset = (\n    train_loader.shuffle(len(x_train))\n    .map(train_preprocessing)\n    .batch(batch_size)\n    .prefetch(1)\n)\n\n# Only rescale.\nvalidation_dataset = (\n    validation_loader.shuffle(len(x_valid))\n    .map(validation_preprocessing)\n    .batch(batch_size)\n    .prefetch(1)\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Flatten, Activation, RepeatVector, Permute, Multiply, Lambda, Dense\n\ndef SE(inputs, ratio = 8):\n    c = np.shape(inputs)[-1]    \n    x = tf.keras.layers.GlobalAveragePooling3D()(inputs)   \n    x = tf.keras.layers.Dense(c//ratio, activation='relu', use_bias=False)(x)\n    x = tf.keras.layers.Dense(c, activation = 'sigmoid', use_bias = False)(x)    \n    x = Multiply()([inputs, x])   \n    return x\n\ndef attBlock(input_tensor):\n    k = Dense(1)(input_tensor)\n    q = Dense(1)(input_tensor)\n    v = Dense(1)(input_tensor)\n    alpha = tf.keras.layers.Activation('softmax')(Multiply()([k, q]))\n    c = Multiply()([alpha, v])\n    return c\n\ndef SE_resBlock(input_tensor, n_filters):\n    x = tf.keras.layers.BatchNormalization()(input_tensor)\n    x = tf.keras.activations.relu(x)\n    x = tf.keras.layers.Conv3D(filters=n_filters , kernel_size=(3,3,3), padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.activations.relu(x)\n    x = tf.keras.layers.Conv3D(filters=n_filters ,kernel_size=(3,3,3) , padding='same')(x)\n    x = SE(x)\n    output_tensor = x + tf.keras.layers.Conv3D(filters=n_filters , kernel_size=(1,1,1))(input_tensor)\n    model = tf.keras.models.Model(input_tensor, output_tensor)\n    return model, output_tensor\n\ndef model_arch():\n    inp = tf.keras.Input((128,128,128,1))\n    x = tf.keras.layers.Conv3D(filters=16 , kernel_size=(3,3,3), padding='same')(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.activations.relu(x)\n    x = tf.keras.layers.Conv3D(filters=16 , kernel_size=(3,3,3), padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.activations.relu(x)\n    m, o = SE_resBlock(x, 32)\n    m, o = SE_resBlock(o, 32)\n    m, o = SE_resBlock(o, 32)\n    x = tf.keras.layers.MaxPooling3D((7,7,7))(o)\n    x1 = attBlock(x)\n    x2 = attBlock(x)\n    x3 = attBlock(x)\n    x = tf.keras.layers.Concatenate()([x1, x2, x3])\n    x = Flatten()(x)\n    x = Dense(128, activation = 'relu')(x)\n    x = Dense(16, activation = 'relu')(x)\n    x = tf.keras.layers.Dropout(0.25)(x)\n    x = Dense(1, activation = 'sigmoid')(x)\n    \n    return tf.keras.models.Model(inp, x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MASERes = model_arch()\ntf.keras.utils.plot_model(MASERes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MASERes.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MASERes = model_arch()\nMASERes.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-6),\n                   loss='binary_crossentropy', metrics = ['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_filepath = '/kaggle/working/'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = MASERes.fit(train_dataset,\n                    validation_data = validation_dataset,\n                    epochs = 100,\n                    verbose = 1,\n                    callbacks=[model_checkpoint_callback])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plot acc and loss\n\nMASERes.save('/kaggle/working/MASERes.h5')\n\nepochs = range(len(history.history['loss']))\nplt.plot(epochs , history.history['loss'], label='Training Loss')\nplt.plot(epochs , history.history['val_loss'], label='Validation Loss')\nplt.title('loss')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs , history.history['acc'], label='Training Accuracy')\nplt.plot(epochs , history.history['val_acc'], label='Validation Accuracy')\nplt.title('accuracy')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MASERes.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6) , \n                loss='binary_crossentropy', metrics = ['acc',\n                                                      tf.keras.metrics.AUC(),\n                                                      tf.keras.metrics.Precision(),\n                                                      tf.keras.metrics.Recall(),\n                                                      tf.keras.metrics.TruePositives(),\n                                                      tf.keras.metrics.TrueNegatives(),\n                                                      tf.keras.metrics.FalsePositives(),\n                                                      tf.keras.metrics.FalseNegatives()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = MASERes.evaluate(validation_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conf_mx = [[a[6], a[7]],[a[8], a[5]]]\nmx = np.array(conf_mx)\nfscore = 2*a[3]*a[4]/(a[3]+a[4])\nspc = mx[0, 0] * 1.0 / (mx[0, 0] + mx[0, 1])\nsen = mx[1,1] * 1.0 / (mx[1,1] + mx[1,0])\n\nprint('accuracy:',np.round(a[1]*100,2),'%')\nprint('precision:',np.round(a[3]*100,2),'%')\nprint('recall:',np.round(a[4]*100,2),'%')\nprint('Sensitivity:',np.round(sen*100,2),'%')\nprint('Specificity:',np.round(spc*100,2),'%')\nprint('f1-score:',np.round(fscore*100,2),'%')\nprint('AUC:',np.round(a[2]*100,2),'%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'/kaggle/working/MASERes.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}